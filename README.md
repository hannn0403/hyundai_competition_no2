# hyundai_competition_no2

This repository implements an end-to-end OCR pipeline to recognize alphanumeric text from images using a TPSâ€‘ResNetâ€‘BiLSTMâ€‘Attention model with data augmentation.

## â—ï¸ Project Summary

---

1. **ì§„í–‰ê¸°ê°„:** 2022.01 ~ 2022.02
2. **íŒ€ëª…: í˜„ëŒ€ì¤‘ê³µì—…ë–¡ìƒê¸°ì›** (í•œì£¼í˜, ì°¨ì¤€ì˜, ê¹€ë¯¼ì„±)
3. **ì—­í• :** í”„ë¡œì íŠ¸ ë¦¬ë”, ì™¸ë¶€ ë°ì´í„° ìˆ˜ì§‘ ë° ìƒˆë¡œìš´ ë°ì´í„° ìƒ˜í”Œ ìƒì„±
4. **ê¸°ìˆ ìŠ¤íƒ: `Python`**, **`PyTorch`**, **`timm`** 
5. **ê²°ê³¼ ë° ì„±ê³¼:** 
    - ìµœì¢…ë³´ê³ ì„œ [**[ğŸ“„]**](https://drive.google.com/file/d/1A59tbe-t8AxI-XemlvMK8jSnxUAGaznz/view?usp=drive_link)
    - https://github.com/hannn0403/hyundai_competition_no2
    - [í˜„ëŒ€ì¤‘ê³µì—…ê·¸ë£¹] ì œ 2íšŒ ì¡°ì„ /í•´ì–‘ì‚°ì—… ë””ì§€í„¸ í˜ì‹ ì„ ìœ„í•œ Big Data / AI ëŒ€í•™ìƒ ê²½ì§„ëŒ€íšŒ ì¥ë ¤ìƒ ìˆ˜ìƒ.
6. **ì£¼ìš”ë‚´ìš©:** ê°•ì¬ ë¬¸ì ì¸ì‹ ê³¼ì œì—ì„œëŠ” HandWritten Data 7,732ê°œì™€ Printing Data 300ê°œë¡œ ì¸í•œ ê·¹ì‹¬í•œ ë°ì´í„° ë¶ˆê· í˜•ê³¼ HandWritten Dataì—ì„œ ê¸€ì êµµê¸°ê°€ ì§€ë‚˜ì¹˜ê²Œ ë‘êº¼ì›Œ ì‹ë³„ì´ ì–´ë ¤ìš´ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, EMINSTì™€ Chars 74K Dataë¥¼ ì¶”ê°€ ìˆ˜ì§‘í•˜ì—¬ ë‘ ë°ì´í„°ì…‹ì„ ë³´ì™„í•œ í›„, Morphological Transformationê³¼ Unsharp Masking ê¸°ë²•ì„ í™œìš©í•˜ì—¬ ì´ë¯¸ì§€ ìƒ¤í”„ë‹ ì²˜ë¦¬ë¥¼ ì§„í–‰í•˜ì˜€ë‹¤. ì´í›„ TPS Spatial Transformation, ResNet Feature Extraction, Bidirectional LSTM, Attention Predictionìœ¼ë¡œ êµ¬ì„±ëœ OCR íŒŒì´í”„ë¼ì¸ì„ ì ìš©í•˜ì—¬ ëª¨ë¸ì„ í•™ìŠµ ë° ì˜ˆì¸¡í•˜ì˜€ê³ , 79.21%ì˜ Accuracyì™€ 95.55%ì˜ 1-NEDë¥¼ ë‹¬ì„±í•˜ì˜€ë‹¤.

---

## Prerequisites

- Python 3.7+
- PyTorch
- torchvision
- nltk
- scikit-learn
- torch.utils.tensorboard (TensorBoard)
- tqdm
- Pillow

Install dependencies:
```bash
pip install torch torchvision nltk scikit-learn tensorboard tqdm pillow
```

## Repository Structure

```
project_root/
â”œâ”€â”€ code/                    # (optional helper scripts)
â”‚   â”œâ”€â”€ augmentation/        # data augmentations
â”‚   â”‚   â”œâ”€â”€ blur.py          # DefocusBlur, MotionBlur
â”‚   â”‚   â””â”€â”€ noise.py         # GaussianNoise, ShotNoise
â”‚   â”œâ”€â”€ model/               # modules for sequence modeling
â”‚   â”‚   â”œâ”€â”€ feature_extraction.py
â”‚   â”‚   â”œâ”€â”€ prediction.py
â”‚   â”‚   â”œâ”€â”€ sequence_modeling.py
â”‚   â”‚   â””â”€â”€ transformation.py
â”œâ”€â”€ config.py                # hyperparameter definitions (args)
â”œâ”€â”€ converter.py             # textâ€‘toâ€‘index and indexâ€‘toâ€‘text converter
â”œâ”€â”€ dataset.py               # Custom Dataset & collate functions
â”œâ”€â”€ ocrmodel.py              # OCRModel definition (TPSâ€‘ResNetâ€‘BiLSTMâ€‘Attn)
â”œâ”€â”€ train.py                 # Main training script
â”œâ”€â”€ result.py                # Inference and result export script
â”œâ”€â”€ datasets/                # data folders
â”‚   â”œâ”€â”€ train/
â”‚   â””â”€â”€ test/
â”œâ”€â”€ weights/                 # (optional) preâ€‘trained weights
â””â”€â”€ result.csv               # final predictions on the test set
```

## Data Preparation

Place your data under the `datasets/` directory:

```
datasets/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ <class_folder>/      # e.g. alphanumeric categories or source batches
â”‚   â”‚   â”œâ”€â”€ image1.jpg
â”‚   â”‚   â”œâ”€â”€ image2.jpg
â”‚   â”‚   â””â”€â”€ annotations.txt  # tabâ€‘separated lines: <filename>\t<label>
â””â”€â”€ test/
    â”œâ”€â”€ <class_folder>/      # same structure without labels (optional)
    â”‚   â”œâ”€â”€ imageA.jpg
    â”‚   â””â”€â”€ imageB.jpg
```

The training script (`train.py`) will scan each `train/<folder>/annotations.txt`, read lines of the form:
```
image_filename\tLABEL_STRING
```
and load corresponding images.

## Configuration

Edit `config.py` to customize hyperparameters. Typical entries include:
```python
args.gpu             = 0
args.save_model_name = "experiment1"
args.epochs          = 200
args.batch           = 64
args.lr              = 1.0
args.rho             = 0.95
args.eps             = 1e-8
args.seed            = 7777
args.text_max_length = 25
```

Or adjust values in this file before running.

## Training

To train the model, simply run:
```bash
python train.py
```

- **Checkpoints** are saved under `save/<save_model_name>/` (created automatically).
- **Logs** for TensorBoard are written to `log/<save_model_name>/` (created automatically).

Launch TensorBoard to monitor:
```bash
tensorboard --logdir log
```

## Inference

After training, generate predictions on your test set by running:
```bash
python result.py --gpu 0 --load_model save/<save_model_name>/<checkpoint>.pkl
```

Outputs will be aggregated into `result.csv`.

## Notes

- The `train.py` script applies random blur and noise augmentations for robustness.
- Model performance is evaluated using accuracy and normalized edit distance (CER), logged per epoch.

## Acknowledgments

- Based on the TPSâ€‘ResNetâ€‘BiLSTMâ€‘Attention OCR architecture.
- Uses NLTKâ€™s edit distance for error rate computation.
- Data augmentations inspired by common OCR pipelines.
